{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcOK8aNFcPz/VcB+Auoz3U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rimbourouphael/Devoir-NFP103/blob/main/Merge_sort.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Devoir\n",
        "L'objectif de cet exercice est de comparer le temps d'exécution de l'algorithme de tri par fusion (merge sort) lorsqu'il est exécuté de manière séquentielle, parallélisée avec des threads et parallélisée avec des processus.\n",
        "\n",
        "\n",
        "Divisez votre liste en deux parties égales.\n",
        "Utilisez deux threads pour trier chaque moitié de la liste simultanément.\n",
        "Fusionnez ensuite les deux listes triées dans le thread principal.\n",
        "\n",
        "\n",
        "Tout comme avec les threads, divisez votre liste en deux parties égales.\n",
        "Utilisez deux processus pour trier chaque moitié de la liste simultanément.\n",
        "Fusionnez ensuite les deux listes triées dans le processus principal.\n",
        ":\n",
        "Utilisez le module time de Python pour mesurer combien de temps chaque implémentation prend pour trier une liste de N éléments (par exemple, pour N = 10^4, 10^5, 10^6...).\n",
        "\n",
        "\n",
        "Analysez et expliquez les résultats obtenus. Pourquoi l'une des méthodes est-elle plus rapide ou plus lente qu'une autre ? Comment le coût de la création de threads ou de processus affecte-t-il les résultats ? Quel impact le GIL (Global Interpreter Lock) de Python a-t-il sur les threads ?\n",
        "\n",
        "\n",
        "Essayez d'utiliser plus de deux threads ou processus (par exemple, 4, 8, 16...) et observez comment cela affecte les performances."
      ],
      "metadata": {
        "id": "44Kg2OdCNFvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge sort séquentiel"
      ],
      "metadata": {
        "id": "VS4zqrx6OTX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_sort(lst):\n",
        "    # Si la liste est vide ou contient un seul élément, elle est déjà triée\n",
        "    if len(lst) <= 1:\n",
        "        return lst\n",
        "\n",
        "    # Sinon, on divise la liste en deux moitiés\n",
        "    middle = len(lst) // 2\n",
        "    left = lst[:middle]\n",
        "    right = lst[middle:]\n",
        "\n",
        "    # On trie chaque moitié de manière récursive\n",
        "    left = merge_sort(left)\n",
        "    right = merge_sort(right)\n",
        "\n",
        "    # On fusionne les deux moitiés triées\n",
        "    return merge(left, right)\n",
        "\n",
        "def merge(left, right):\n",
        "    result = []\n",
        "    i = j = 0\n",
        "\n",
        "    # Tant que les deux listes contiennent des éléments\n",
        "    while i < len(left) and j < len(right):\n",
        "        if left[i] < right[j]:\n",
        "            result.append(left[i])\n",
        "            i += 1\n",
        "        else:\n",
        "            result.append(right[j])\n",
        "            j += 1\n",
        "\n",
        "    # Si une des listes contient encore des éléments, on les ajoute tous à la liste résultat\n",
        "    while i < len(left):\n",
        "        result.append(left[i])\n",
        "        i += 1\n",
        "    while j < len(right):\n",
        "        result.append(right[j])\n",
        "        j += 1\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "MKKGQnfU_Ven"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge sort avec Threads"
      ],
      "metadata": {
        "id": "LQX2y_uoNnoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "# Fonction pour trier avec des threads\n",
        "def tri_fusion_threads(lst):\n",
        "    if len(lst) <= 1:\n",
        "        return lst\n",
        "\n",
        "    mid = len(lst) // 2\n",
        "    left_half = lst[:mid]\n",
        "    right_half = lst[mid:]\n",
        "\n",
        "    left_thread = threading.Thread(target=merge_sort, args=(left_half,))\n",
        "    right_thread = threading.Thread(target=merge_sort, args=(right_half,))\n",
        "\n",
        "    left_thread.start()\n",
        "    right_thread.start()\n",
        "\n",
        "    left_thread.join()\n",
        "    right_thread.join()\n",
        "\n",
        "    return merge(left_half, right_half)"
      ],
      "metadata": {
        "id": "yHP8JB87_xB9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge sort avec processus"
      ],
      "metadata": {
        "id": "soaLdypMNhsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "# Fonction pour trier avec des processus\n",
        "def tri_fusion_processes(lst):\n",
        "    if len(lst) <= 1:\n",
        "        return lst\n",
        "\n",
        "    mid = len(lst) // 2\n",
        "    left_half = lst[:mid]\n",
        "    right_half = lst[mid:]\n",
        "\n",
        "    with multiprocessing.Pool(2) as pool:\n",
        "        left_half = pool.apply(merge_sort, (left_half,))\n",
        "        right_half = pool.apply(merge_sort, (right_half,))\n",
        "\n",
        "    return merge(left_half, right_half)"
      ],
      "metadata": {
        "id": "OP7jcq6YNgnf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "#D'efinition de la liste a trier\n",
        "lst = [38, 27, 43, 3, 9, 82, 10,78,66,23,2,79]\n",
        "\n",
        "# Tri séquentiel\n",
        "start_time = time.time()\n",
        "sorted_list_sequential = merge_sort(lst.copy())\n",
        "end_time = time.time()\n",
        "print(\"Tri avec séquentiel\\n\\t\" , sorted_list_sequential)\n",
        "print(\"\\tTemps d'exécution (en secondes) :\", end_time - start_time)\n",
        "print(\"=\" * 65)\n",
        "\n",
        "# Tri avec threads\n",
        "start_time = time.time()\n",
        "sorted_list_threads = tri_fusion_threads(lst.copy())\n",
        "end_time = time.time()\n",
        "print(\"Tri avec threads\\n\\t\" , sorted_list_threads)\n",
        "print(\"\\tTemps d'exécution (en secondes) :\", end_time - start_time)\n",
        "print(\"=\" * 65)\n",
        "\n",
        "# Tri avec processus\n",
        "start_time = time.time()\n",
        "sorted_list_processes = tri_fusion_processes(lst.copy())\n",
        "end_time = time.time()\n",
        "print(\"Tri avec processus\\n\\t\" , sorted_list_processes)\n",
        "print(\"\\tTemps d'exécution (en secondes) :\", end_time - start_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "eXvVXiCnAtN-",
        "outputId": "1bc300b7-9e74-43b4-a23d-6c5bd05c48b0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tri avec séquentiel\n",
            "\t [2, 3, 9, 10, 23, 27, 38, 43, 66, 78, 79, 82]\n",
            "\tTemps d'exécution (en secondes) : 9.560585021972656e-05\n",
            "=================================================================\n",
            "Tri avec threads\n",
            "\t [10, 38, 27, 43, 3, 9, 78, 66, 23, 2, 79, 82]\n",
            "\tTemps d'exécution (en secondes) : 0.00661921501159668\n",
            "=================================================================\n",
            "Tri avec processus\n",
            "\t [2, 3, 9, 10, 23, 27, 38, 43, 66, 78, 79, 82]\n",
            "\tTemps d'exécution (en secondes) : 0.030514001846313477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analyse des resultats\n",
        "Les résultats dépendent de la longueur de la liste donnée et du matériel utilisé.\n",
        "En principe: le tri séquentiel est le plus lent, suivi du tri avec des threads (en raison du GIL de Python), tandis que le tri avec des processus peut être le plus rapide, en particulier lorsque plusieurs cœurs de CPU sont disponibles.\n",
        "\n",
        "**Impact du coût de la création de threads ou de processus :**\n",
        "\n",
        "La création de threads est généralement moins coûteuse que la création de processus, car les threads partagent la mémoire de leur processus parent. Cependant, cela dépend du système d'exploitation et du langage de programmation utilisés.\n",
        "La création de processus est plus coûteuse en termes de temps et de mémoire, car chaque processus a sa propre mémoire et son propre espace d'adressage.\n",
        "\n",
        "**Impact du GIL (Global Interpreter Lock) :**\n",
        "\n",
        "Le GIL de Python limite l'exécution concurrente de plusieurs threads dans le même processus Python. Cela signifie que, bien que les threads puissent améliorer les performances dans certains cas, ils ne peuvent pas exploiter pleinement plusieurs cœurs de processeur.\n",
        "En conséquence, les threads Python ne sont pas toujours aussi efficaces pour des tâches fortement parallèles, ce qui limite leur avantage par rapport aux processus"
      ],
      "metadata": {
        "id": "xhPyVfPCKWJG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partie comparaison de plusieurs threads et processus"
      ],
      "metadata": {
        "id": "ulcnL2mDW3Vn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge sort qui supporte plusieurs threads"
      ],
      "metadata": {
        "id": "ZeiGM_mOWcoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "# Fonction pour trier avec des threads\n",
        "def tri_avec_threads(lst, num_threads):\n",
        "    part_size = len(lst) // num_threads\n",
        "    threads = []\n",
        "    partie_trie = []\n",
        "\n",
        "    # Fonction pour trier un morceau de la liste en parallèle\n",
        "    def trierPartie(part):\n",
        "        sorted_part = merge_sort(part)\n",
        "        partie_trie.append(sorted_part)\n",
        "\n",
        "    # Création et démlstage des threads\n",
        "    for i in range(num_threads):\n",
        "        start = i * part_size\n",
        "        end = start + part_size if i < num_threads - 1 else len(lst)\n",
        "        part = lst[start:end]\n",
        "        thread = threading.Thread(target=trierPartie, args=(part,))\n",
        "        threads.append(thread)\n",
        "        thread.start()\n",
        "\n",
        "    # Attente de la fin de tous les threads\n",
        "    for thread in threads:\n",
        "        thread.join()\n",
        "\n",
        "    # Fusion des morceaux triés\n",
        "    sorted_lst = partie_trie[0]\n",
        "    for i in range(1, num_threads):\n",
        "        sorted_lst = merge(sorted_lst, partie_trie[i])\n",
        "\n",
        "    return sorted_lst\n",
        "\n"
      ],
      "metadata": {
        "id": "hKyCOQmoSZI4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge sort qui supporte plusieurs processus"
      ],
      "metadata": {
        "id": "bAglLlcCWlsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "# Fonction pour trier avec des processus\n",
        "def tri_avec_processus(lst, num_processes):\n",
        "    part_size = len(lst) // num_processes\n",
        "    processes = []\n",
        "    partie_trie = []\n",
        "\n",
        "    # Fonction pour trier un morceau de la liste en parallèle\n",
        "    def trierPartie(part, output):\n",
        "        sorted_part = merge_sort(part)\n",
        "        output.put(sorted_part)\n",
        "\n",
        "    # Création et démlstage des processus\n",
        "    for i in range(num_processes):\n",
        "        start = i * part_size\n",
        "        end = start + part_size if i < num_processes - 1 else len(lst)\n",
        "        part = lst[start:end]\n",
        "        output = multiprocessing.Queue()\n",
        "        process = multiprocessing.Process(target=trierPartie, args=(part, output))\n",
        "        processes.append((process, output))\n",
        "        process.start()\n",
        "\n",
        "    # Attente de la fin de tous les processus\n",
        "    for process, output in processes:\n",
        "        process.join()\n",
        "        partie_trie.append(output.get())\n",
        "\n",
        "    # Fusion des morceaux triés\n",
        "    sorted_lst = partie_trie[0]\n",
        "    for i in range(1, num_processes):\n",
        "        sorted_lst = merge(sorted_lst, partie_trie[i])\n",
        "\n",
        "\n",
        "    return sorted_lst"
      ],
      "metadata": {
        "id": "205rYpRJWaR3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Partie main du programme pour l' affichage du temps de chaque fonction de multithreads et multiprocessus"
      ],
      "metadata": {
        "id": "3f6BARu5Wo5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Nombre de threads\n",
        "num_threads = 2\n",
        "# Nombre de processus\n",
        "num_processes = 2\n",
        "\n",
        "lst = lst = [38, 27, 43, 3, 9, 82, 10,78,66,23,2,79]\n",
        "\n",
        "\n",
        "# Tri avec des threads\n",
        "start_time = time.time()\n",
        "sorted_list_threads = tri_avec_threads(lst.copy(), num_threads)\n",
        "end_time = time.time()\n",
        "print(\"Tri avec threads\\n\\t\" , sorted_list_threads)\n",
        "print(\"\\tTemps d'exécution (en secondes) :\", end_time - start_time)\n",
        "print(\"=\" * 65)\n",
        "\n",
        "# Tri avec des processus\n",
        "start_time = time.time()\n",
        "sorted_list_processes = tri_avec_processus(lst.copy(), num_processes)\n",
        "end_time = time.time()\n",
        "print(\"Tri avec processus\\n\\t\" , sorted_list_processes)\n",
        "print(\"\\tTemps d'exécution (en secondes) :\", end_time - start_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ToLDX3lqVDnA",
        "outputId": "3f5f2f64-efd5-414c-f51b-40e8061d97a4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tri avec threads\n",
            "\t [2, 3, 9, 10, 23, 27, 38, 43, 66, 78, 79, 82]\n",
            "\tTemps d'exécution (en secondes) : 0.0005075931549072266\n",
            "=================================================================\n",
            "Tri avec processus\n",
            "\t [2, 3, 9, 10, 23, 27, 38, 43, 66, 78, 79, 82]\n",
            "\tTemps d'exécution (en secondes) : 0.03475809097290039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "l'impact du tri fusion parallèle sur les performances dépend de plusieurs facteurs, notamment la taille des données, le nombre de cœurs ou de processeurs disponibles, la complexité de la fusion, la gestion de la mémoire et la synchronisation. Pour de grandes quantités de données avec un matériel adapté, le tri fusion parallèle peut offrir une amélioration significative des performances par rapport à l'exécution séquentielle. Cependant, pour de petites quantités de données ou avec des contraintes de ressources, l'utilisation de plusieurs threads ou processus peut ne pas être aussi bénéfique et peut même entraîner une perte de performance due à l'overhead de la gestion concurrente."
      ],
      "metadata": {
        "id": "3ASdMOBOPkTI"
      }
    }
  ]
}